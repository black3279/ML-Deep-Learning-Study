# 통계및머신러닝
## 9) 머신러닝
### 머신러닝의 종류
- 지도 학습이란 학습 데이터 안에 입력값에 대한 출력값이 함께 제시되는 걸 말한다
  - 출력값이 수치형인 회귀와 범주형인 분류 문제로 나누어 진다
- 비지도 학습이란 학습 데이터 안에 출력값이 없는 것으로 적절한 군집을 찾거나 차원 축소 등이 이에 속한다
- 강화학습이란 지시가 없이 목표만 주어지며 Agent 가 존재하여 Reward 를 최대화하는 방향으로 학습한다
  - 데이터에서 보지 못한 내용에도 적용하여 반복하면서 더 좋은 결과를 낼 수 있다
- Semi-supervised Learning : unsupervised 로 clustering 하여 가장 성능이 좋은 그룹으로 나누고 파생변수로 feature 를 새롭게 달아주어 출력값을 달아주는 방법이다
- Transfer Learning 이란 만들어진 모델을 끌고와서 사용하는 기법이다

### Feature Engineering
- 데이터를 준비하는 과정에서 시행하는 특징 추출이다
- 원시데이터를 다루고 있는 문제를 더 잘 표현할 수 있게 데이터를 사전에 특징으로 변환하는 과정이다
- 더 유연한 모델, 더 단순한 모델, 더 좋은 결과를 기대하기 위해 Feature Engineering 이 중요하다
- Feature 의 중요도를 객관적으로 측정할 수 있는 지표에는 상관 계수, 회귀 계수와 p-value, 의사결정 나무 가 있다
- Feature 가 많은 경우 버리는 경우도 있다
- Feature Extraction, Feature Construction, Feature Learning 은 Raw 데이터로부터 새로운 Feature 를 만들어 내는 경우이다
  - Feature Extraction 은 간단한 수식으로 데이터를 분류하는 자동화의 개념이다
  - Feature Construction 은 사람의 회의 등 수작업의 개념이다
  - Feature Learning 은 머신러닝으로 새로운 데이터를 만들어내는 개념이다
- 일반화 오류는 예측 오류(테스트 데이터를 모델에 적용하여 측정한 오류) 로 대체하여 추정한다
- 편향이란 예측값이 정답과 얼마나 다른가를 말하며 분산은 예측값들이 얼마나 흩어져있는가를 나타낸다
- 입력변수가 증가하거나 출력 변수의 가능한 class 가 늘어나거나 입/출력변수 간 관계가 비선형이면 모델의 복잡도가 증가한다
- 과소적합이란 모델의 복잡도가 너무 낮은 것으로 학습시간을 늘리거나 더 복잡한 모델을 구성한다
- 과대적합이란 모델의 복잡도가 너무 높아 일반화에 실패하는 것으로 Regularization 을 활용해 일부 Feature 를 제거할 수 있다
- 데이터 비대칭 문제를 해결하기 위해서는 데이터를 추가확보하거나 Re-sampling 하거나 패널티가 있는 함수를 사용할 수 있다
- Re-sampling 이란 상대적으로 많이 나타나는 클래스의 개수를 줄이는 과소표집의 개념이 있다
  - 데이터를 복제하여 데이터 개수를 늘리는 과대표집 방법도 있는데 과적합 위험을 피하기 위해 SMOTE 와 같은 방법을 사용한다
- SMOTE 란 합성소수 과대표집 기법으로 표본을 복원 추출하는 부트스트래핑이나 KNN 모델 기법을 사용한다
- 충분히 큰 데이터가 없을 때에는 교차확인 (Cross Validation) 을 고려한다
  - Hold-out 이란 Train 과 Test 세트를 한번만 나누어 사용하는 것을 말한다 ( Train-Validation-Test 가능 )
  - Cross Validaiton (교차검증) 이란 k-fold Cross Validation 이라고도 하며 일반적으로 k = 10 을 넣는다
  - 같은 데이터와 같은 알고리즘이어도 데이터를 어떻게 분할하냐에 따라 정확도가 다르게 나올 수 있다 따라서 k-fold 는 분할, 트레이닝,테스트를 10번으로 나누어 시행하여 bias 를 해결한다
- 회귀모델 평가지표에는 MSE, RMSE, MAE, MAPE 가 있다
- 분류모델에서 Precision 이란 내가 True 라고 예측했을 때 실제 True 일 비율이다
- 분류모델에서 Recall 이란 실제 True 중에 내가 True 를 맞출 비율을 의미한다
- 이외에 F-measure, G 수치 값, 해석력, 효율성, 안정성을 통해 모델을 평가한다
- 