- 범주형 변수 2개의 연관성은 분할표로 분석 가능
- 변동계수는 표준편차를 산술평균으로 나눈 것이다
- 사분위수 범위=Q3?Q1
- 연속형 확률변수의 확률밀도 함수는 0 ~ 1 의 범위를 갖는다
- 정규분포를 확인하는 방법에는 히스토그램, 정규분포 plot, Q-Q plot 과 같은 방법이 있다
- 독립인 변수는 상관계수가 0 이지만 상관계수가 0 이라고해서 독립을 의미하는 것은 아니다
- 1~2개 그룹 간 평균 검정에는 T-test, One Sample, Paired, Two sample 검정을 한다
- 2개 이상의 그룹 간 평균 검정에는 ANOVA, One Way, Two way 검정을 한다
- 범주형 변수의 독립성 검정에는 카이제곱 검정을 한다
- 수치형 변수 간 선형관계에는 상관분석을 사용한다
- 한 수치형 변수와 N개의 변수 간 관계에는 회귀분석을 사용한다
- 표본을 늘리면 신뢰구간이 줄어든다
- Classification 은 비용함수에서 주로 Maximize likelihood, Minimize Cross-entrophy 를 사용한다
- Naive Bayesian 에서는 데이터의 개수가 적을 때 과적합될 가능성이 높다
- F1-measure 는 2*Precision*Recall / (Precision + Recall) 이다
- G-measure 는 제곱근(Precision*Recall) 이다
- Forward Selection 에서 입력변수를 점진적으로 추가하는 이유는 계산량을 줄이기 위해서이다
- 의사결정나무에서 같은 정확도를 갖는다면 노드의 수가 적은 것이 좋고 Tree 노드 수가 증가할수록 학습데이터 (테스트 데이터 X) 에 대한 정확도는 향상되는 경향이 있다
- 층화추출이란 모집단의 각 층의 비율만큼 추출하는 것이며 각 층에서는 단순임의추출을 사용한다
- 계통추출이란 매 k 번째 요소를 표본으로 하는 것이며 주기성이 있는 경우는 사용하지 않는다
- 회귀모형이 통계적으로 유의미한지는 F 검정을 사용한다
- 회귀모형의 회귀변수들이 유의미한지는 t 검정을 실시한다
- Outlier 확인 방법에는 1사분위수 - 1.5*IQR, 3사분위 + 1.5*IQR 로 하한과 상한을 정하는 방법이 있다
- 기하평균 +- (2.5*표준편차) 를 벗어난 범위로 이상치를 인식할수도 있다
- ANOVA 검정 이후에 사후검은 nC2 만큼의 가설의 개수가 만들어진다
- Ward 연결 방법이란 최소분산연결법을 말한다
- Box plot 상자그림은 연속형 자료에 대한 그래프이다
- 연속형 확률변수에서 한 점에 대한 확률은 0 이며 특정값의 개수 비율이 아닌 범위의 면적으로 계산한다
- 상관계수가 1이어도 회귀 기울기는 1이 아닐 수 있다
- t 검정을 수행하기위해서는 모집단의 정규분포 가정이 필요하다
- 동일 집단의 전과 후의 비교에는 Pared t-test 가 적당하다
- 일반적으로 조사 또는 실험으로 주장하고자 하는 사실을 대립가설로 한다
- 카이제곱, F, 지수 분포는 연속 확률 분포이며 포아송 분포는 이산확률분포이다
- 평균치에 차이가 없다는 검정은 (평균1-평균2)/제곱근(표준편차1 제곱/N + 표준편차2 제곱/N) 으로 구한다
- Hierarchical Clustering 은 K-meas 대비 상대적으로 이상치의 영향을 덜 받는다
- 지지도는 X 와 Y 의 곱확률이다
- 단순임의추출기법은 모집단에 대한 사전 지식을 사용하지 않기 때문에 추출된 표본의 대표성이 상대적으로 높다
- WLS 는 등분산성 해결의 방법이다
- Bayes 정리를 사용하면 P(X|Y) = P(Y|X)*P(X) / P(Y) 로 바꿀 수 있다
- 두 변수의 분산의 등분산 여부(분산차이)를 확인하기 위해 분산의 비로 나타낼 수 있는 분포는 F 분포 이다
- 군집추출, 집락추출이란 군집 간 동질성을 지니고 군집 내 이질성을 지닌 군집을 추출할때 사용하는 기법이다
- 선형회귀분석의 가정 중 선형성만 종속변수와 독립변수에 대한 것이고 정규성, 등분산성, 독립성은 오차에 관련된 가정이다
- 분류기법의 평가지표에 대한 설명은 다음과 같다
- 정확도 Accurancy 는 모든 가능한 수에 대비한 Tp 와 Tn 의 비율을 말한다
- 정밀도 Precision 은 Tp / (Tp + Fp) 이다
- 재현율 Recall 은 Tp / (Tp + Fn) 이다
- F-score 는 2*Precision*Recall / (Precision + Recall) 이다
- G-score 는 제곱근(Precision*Recall) 이다
- KNN, 의사결정나무, Naive Bayes, Logistic 등은 지도학습 기법이다
- Clustering, Association Rule, Dimension Reduction 은 비지도학습 기법이다
- Hierarchical Clustering (계층적 군집분석) 은 최단 연결법 등으로 군집을 병합하는 방법을 말한다
- 비계층적 군집분석에는 K-means Clustering 과 같은 방법이 있다
- 계층적 군집분석에는 거리 개념이 쓰이며 랜덤 포레스트란 복수의 의사결정 나무로 병렬로 처리 (Bagging) 하는 방법이라고 보면 된다
- 로지스틱 회귀분석에서 회귀계수의 양, 음에 따라 상관관계를 의미하지만 독립변수의 변화에 따른 종속변수 값에 미치는 영향이 아니라 log(odds) 의 변화량을 의미한다
- 계층적, 비계층적 군집방법 모두 군집의 개수를 정해야하며 다른 Feature 를 기준으로 거리를 계산하면 군집결과가 다르게 생성될 수 있다
- K-means Clustering은 어떤 경우에도 K 개 군집을 만들어낸다
- 분류나무의 불순도 계산방법은 Entropy Reduction, Gini Reduction, Chi-square test 가 있다
-Gini 불순도는 전체에서 각 데이터의 비율을 구해서 1 - 해당 데이터의 비율 제곱 으로 계산을 먼저한다
- 이후에 해당 개별 구간에서 각 데이터의 비율을 구한 후 1 - 해당 데이터의 비율의 제곱으로 계산하여 각 구간을 구한다
- 전체 불순도에서 해당 구간별 불순도 * 전체에서 해당 데이터가 차지하는 비율 로 모두 빼주면 Gini 불순도를 계산할 수 있다
- ANOVA 에서 총변동성 SST = 오차에의한 변동 SSE ( 그룹 내 변동) + 요인에 의한 변동 SSTR ( 그룹 간 변동) 으로 계산한다 => SSTR 의 크기로 집단 별 모평균 차이를 파악 가능하다
- 그룹 간 변동 SSTR 의 경우 전체 평균에서 각 그룹 평균을 뺀 잔차의 제곱에 해당 그룹의 표본 갯수를 곱하여 더한다
- 그룹 간 자유도는 k-1 , 그룹 내 자유도는 n-k 이다, k 는 그룹의 개수이다
- MSTR = SSTR/(k-1) 이며 MSE = SSE/(n-k) 이다
- F 값은 MSTR/MSE 이다
- 단순지수 평활법에서 일반적으로 이전 예측 값이 없으면 해당 년도 값을 그대로 사용한다
- KNN 방법에서 거리는 절대거리(맨하탄) 으로 계산하면 되며 k 의 개수만큼 이웃을 구한 후 다수결로 결정한다
- 계층적 군집분석을 사용할때는 점 별로 거리를 모두 구한 후에 병합하고 병합한 집단간의 거리도 해당 속한 점 중 최단거리로 병합하면 된다
- 비계층적 군집분석 K-means 에서는 거리가 더 짧은 쪽으로 속하도록 분배한다