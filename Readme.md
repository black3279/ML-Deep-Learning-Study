 # 머신러닝 딥러닝 스터디
## 머신러닝이란 컴퓨터 프로그램이 데이터와 처리 경험을 이용한 학습을 통해 정보 처리 능력을 향상시키는 것과 관련된 분야를 말한다

- 1959년 아서 사무엘에 의해서 해당 용어가 대중화되었으며 카네기 멜론 대학 컴퓨터 과학 교수인 톰 미첼에 의해서 "어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P 로 측정했을 때 경험 E 로 인 해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다" 라고 정의되었다

### 생각하는 뇌, 생각하는 기계 - 제프 호킨스 에서는 지능이 무엇인지에 대해 설명하는데, 창조가 유추를 통한 예측이라고 말한다.

- 기계들은 '코드'를 이용해서 포토샵, 비디오 편집, 워드, 엑셀, 등등의 수 많은 일들을 할 수 있다. 그러면 AI가 사람이 할 수 있는 행동들을 하게되면 그 존재는 지적인 존재인가 ?
- 지능이란 무엇인가 ? 그는 일종의 '이해' '학습' 에서 이를 찾아본다.
- 예를 보자. 방에 책상과 책 하나 사람 한 명이 있다. 책에는 알 수 없는 언어가 있고 그 언어가 입력되면 이렇게 써라 라는 매뉴얼적인 내용이 있다. 그리고 방 안으로 종이가 들어온다. 그 종이에는 알 수 없는 언어가 쓰여있고 방 안에 있는 사람은 책을 보며 매뉴얼 내용을 따라서 옮겨 쓴 후 종이를 내보낸다. 그리고 밖에서 이를 본 사람은 방 안에 있는 사람이 해당 언어를 완전히 이해했으며 통찰력까지 보인다고 평가한다. 그렇다면 방 안에 있는 사람은 지적인 존재인가? 일반적으로 생각했을 때는 아닐 것 이다.
- 지적인 존재는 사람과 같은 감각기관에 제한될 필요가 없으며 초음파, 적외선 등등 필요에 따라 다른 수족을 사용할 수 있다.
- 신피질 알고리즘을 이해해 각각의 감각에 맞춰 사용될 수 있는 세포 알고리즘을 이용할 수 있다는 생각과 함께, 끊임없는 두뇌 작용과 되먹임(Feedback)을 통해 학습하고, 유추를 통해 예측하는 지적인 존재를 만들어야한다고 주장한다.
- ## 지도학습과 비지도학습, 강화학습

- 지도 학습이란 학습 데이터 안에 입력값에 대한 출력값이 함께 제시되는 걸 말한다
    - 출력값이 수치형인 회귀와 범주형인 분류 문제로 나누어 진다
- 비지도 학습이란 학습 데이터 안에 출력값이 없는 것으로 적절한 군집을 찾거나 차원 축소 등이 이에 속한다
- 강화학습이란 지시가 없이 목표만 주어지며 Agent 가 존재하여 Reward 를 최대화하는 방향으로 학습한다
    - 데이터에서 보지 못한 내용에도 적용하여 반복하면서 더 좋은 결과를 낼 수 있다
- Semi-supervised Learning : unsupervised 로 clustering 하여 가장 성능이 좋은 그룹으로 나누고 파생변수로 feature 를 새롭게 달아주어 출력값을 달아주는 방법이다
- Transfer Learning 이란 만들어진 모델을 끌고와서 사용하는 기법이다

## 머신러닝의 기법

### Feature Engineering

- 데이터를 준비하는 과정에서 시행하는 특징 추출이다
- 원시데이터를 다루고 있는 문제를 더 잘 표현할 수 있게 데이터를 사전에 특징으로 변환하는 과정이다
- 더 유연한 모델, 더 단순한 모델, 더 좋은 결과를 기대하기 위해 Feature Engineering 이 중요하다
- Feature 의 중요도를 객관적으로 측정할 수 있는 지표에는 상관 계수, 회귀 계수와 p-value, 의사결정 나무 가 있다
- Feature 가 많은 경우 버리는 경우도 있다
- Feature Extraction, Feature Construction, Feature Learning 은 Raw 데이터로부터 새로운 Feature 를 만들어 내는 경우이다
    - Feature Extraction 은 간단한 수식으로 데이터를 분류하는 자동화의 개념이다
    - Feature Construction 은 사람의 회의 등 수작업의 개념이다
    - Feature Learning 은 머신러닝으로 새로운 데이터를 만들어내는 개념이다

## 편향이란 예측값이 정답과 얼마나 다른가를 말하며 분산은 예측값들이 얼마나 흩어져있는가를 나타낸다

- 일반화 오류(새로운 데이터 추출하여 적용 시 예상되는 오류)는 예측 오류(테스트 데이터를 모델에 적용하여 측정한 오류) 로 대체하여 추정한다
- 입력변수가 증가하거나 출력 변수의 가능한 class 가 늘어나거나 입/출력변수 간 관계가 비선형이면 모델의 복잡도가 증가한다
- 과소적합이란 모델의 복잡도가 너무 낮은 것으로 학습시간을 늘리거나 더 복잡한 모델을 구성한다
- 과대적합이란 모델의 복잡도가 너무 높아 일반화에 실패하는 것으로 Regularization 을 활용해 일부 Feature 를 제거할 수 있다
- 데이터 비대칭 문제를 해결하기 위해서는 데이터를 추가확보하거나 Re-sampling 하거나 패널티가 있는 함수를 사용할 수 있다
- Re-sampling 이란 상대적으로 많이 나타나는 클래스의 개수를 줄이는 과소표집의 개념이 있다
    - 데이터를 복제하여 데이터 개수를 늘리는 과대표집 방법도 있는데 과적합 위험을 피하기 위해 SMOTE 와 같은 방법을 사용한다
- SMOTE 란 합성소수 과대표집 기법으로 표본을 복원 추출하는 부트스트래핑이나 KNN 모델 기법을 사용한다
- 충분히 큰 데이터가 없을 때에는 교차확인 (Cross Validation) 을 고려한다
    - Hold-out 이란 Train 과 Test 세트를 한번만 나누어 사용하는 것을 말한다 ( Train-Validation-Test 가능 )
    - Cross Validaiton (교차검증) 이란 k-fold Cross Validation 이라고도 하며 일반적으로 k = 10 을 넣는다
    - 같은 데이터와 같은 알고리즘이어도 데이터를 어떻게 분할하냐에 따라 정확도가 다르게 나올 수 있다 따라서 k-fold 는 분할, 트레이닝,테스트를 10번으로 나누어 시행하여 bias 를 해결한다
- 회귀모델 평가지표에는 MSE, RMSE, MAE, MAPE 가 있다
- 분류모델에서 Precision 이란 내가 True 라고 예측했을 때 실제 True 일 비율이다
- 분류모델에서 Recall 이란 실제 True 중에 내가 True 를 맞출 비율을 의미한다
- 이외에 F-measure, G 수치 값, 해석력, 효율성, 안정성을 통해 모델을 평가한다
 
 ### NOTION https://polyester-trip-9ae.notion.site/419d44a859b04385841272fb218cc0e6
 ### 21/10/20 ADD https://polyester-trip-9ae.notion.site/4e6f255990ca4d9b91e94741f29a93bf (LAST UPDATE 21/10/22)
